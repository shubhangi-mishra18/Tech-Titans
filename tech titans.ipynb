{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8651bff2-bce4-4c7a-83dc-1f5b6796bc14",
   "metadata": {},
   "source": [
    "# Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269819d-8f34-4bbb-897b-68aca4cadaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"D:\\SMS-Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23883acc-3c6f-4e6e-9499-93c6f9cc9502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>id</th>\n",
       "      <th>updateAt</th>\n",
       "      <th>senderAddress</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xx39973810</td>\n",
       "      <td>baa1668c-049e-4118-938e-cc804f1e73aa</td>\n",
       "      <td>Sat, 7 May 2022 19:48:00 UTC</td>\n",
       "      <td>JK-SmplPL</td>\n",
       "      <td>Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xx39973810</td>\n",
       "      <td>baa1668c-049e-4118-938e-cc804f1e73aa</td>\n",
       "      <td>Sat, 7 May 2022 19:48:00 UTC</td>\n",
       "      <td>VP-ViCARE</td>\n",
       "      <td>Hi! Update your email id through WhatsApp: htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx39973810</td>\n",
       "      <td>baa1668c-049e-4118-938e-cc804f1e73aa</td>\n",
       "      <td>Sat, 7 May 2022 19:48:00 UTC</td>\n",
       "      <td>VP-612345</td>\n",
       "      <td>Lucknow ya Kolkata ? - watch it LIVE with Vi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xx39973810</td>\n",
       "      <td>baa1668c-049e-4118-938e-cc804f1e73aa</td>\n",
       "      <td>Sat, 7 May 2022 19:48:00 UTC</td>\n",
       "      <td>BP-ACKOGI</td>\n",
       "      <td>Mohd,\\nCheck the incredible Acko insurance pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xx39973810</td>\n",
       "      <td>baa1668c-049e-4118-938e-cc804f1e73aa</td>\n",
       "      <td>Sat, 7 May 2022 19:48:00 UTC</td>\n",
       "      <td>VP-ViCARE</td>\n",
       "      <td>Hi! You can now get your Vi prepaid invoice em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  phoneNumber                                    id  \\\n",
       "0  xx39973810  baa1668c-049e-4118-938e-cc804f1e73aa   \n",
       "1  xx39973810  baa1668c-049e-4118-938e-cc804f1e73aa   \n",
       "2  xx39973810  baa1668c-049e-4118-938e-cc804f1e73aa   \n",
       "3  xx39973810  baa1668c-049e-4118-938e-cc804f1e73aa   \n",
       "4  xx39973810  baa1668c-049e-4118-938e-cc804f1e73aa   \n",
       "\n",
       "                       updateAt senderAddress  \\\n",
       "0  Sat, 7 May 2022 19:48:00 UTC     JK-SmplPL   \n",
       "1  Sat, 7 May 2022 19:48:00 UTC     VP-ViCARE   \n",
       "2  Sat, 7 May 2022 19:48:00 UTC     VP-612345   \n",
       "3  Sat, 7 May 2022 19:48:00 UTC     BP-ACKOGI   \n",
       "4  Sat, 7 May 2022 19:48:00 UTC     VP-ViCARE   \n",
       "\n",
       "                                                text  \n",
       "0  Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...  \n",
       "1  Hi! Update your email id through WhatsApp: htt...  \n",
       "2  Lucknow ya Kolkata ? - watch it LIVE with Vi c...  \n",
       "3  Mohd,\\nCheck the incredible Acko insurance pol...  \n",
       "4  Hi! You can now get your Vi prepaid invoice em...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad073d-0811-4053-880f-1e6cfe4a68ac",
   "metadata": {},
   "source": [
    "# Remove Unwanted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c65bf6-4efa-4d71-b1ce-f1536f100802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       senderAddress                                               text  \\\n",
      "0          JK-SmplPL  Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...   \n",
      "1          VP-ViCARE  Hi! Update your email id through WhatsApp: htt...   \n",
      "2          VP-612345  Lucknow ya Kolkata ? - watch it LIVE with Vi c...   \n",
      "3          BP-ACKOGI  Mohd,\\nCheck the incredible Acko insurance pol...   \n",
      "4          VP-ViCARE  Hi! You can now get your Vi prepaid invoice em...   \n",
      "...              ...                                                ...   \n",
      "100227     AD-SECRRE  Hi Work 30 mins daily using your mobile phone ...   \n",
      "100229     JD-JIOINF  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...   \n",
      "100235     JD-JIOINF  IMPORTANT: Beware of the fraudulent messages a...   \n",
      "100236     AD-KJRIWL  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...   \n",
      "100238     JD-AKAMAH  As we celebrate Azadi Ka Amrit Mahotsav, let's...   \n",
      "\n",
      "       phoneNumber                      updateAt  \n",
      "0       xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "1       xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "2       xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "3       xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "4       xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "...            ...                           ...  \n",
      "100227  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "100229  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "100235  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "100236  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "100238  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "\n",
      "[87504 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where senderAddress starts with an alphabet (case-insensitive)\n",
    "filtered_df = df[df['senderAddress'].str.match(r'^[A-Za-z]', na=False)]\n",
    "\n",
    "# Print the filtered rows with both 'senderAddress' and 'text' columns\n",
    "print(filtered_df[['senderAddress', 'text','phoneNumber','updateAt']])\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "filtered_df[['senderAddress', 'text','phoneNumber','updateAt']].to_csv('filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851cda6-b698-4a86-ac59-dec3d9105d1b",
   "metadata": {},
   "source": [
    "#  Count of Unique Phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "883bc1a0-a7c0-4f47-9716-4392a5983666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93 unique phone numbers.\n"
     ]
    }
   ],
   "source": [
    "unique_phone_numbers = df['phoneNumber'].nunique()\n",
    "\n",
    "# Print the number of unique phone numbers\n",
    "print(f'There are {unique_phone_numbers} unique phone numbers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53fa2e80-40f3-486d-adb5-f4e9bc7edcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      senderAddress                                               text  \\\n",
      "0         JK-SmplPL  Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...   \n",
      "1         VP-ViCARE  Hi! Update your email id through WhatsApp: htt...   \n",
      "2         VP-612345  Lucknow ya Kolkata ? - watch it LIVE with Vi c...   \n",
      "3         BP-ACKOGI  Mohd,\\nCheck the incredible Acko insurance pol...   \n",
      "4         VP-ViCARE  Hi! You can now get your Vi prepaid invoice em...   \n",
      "...             ...                                                ...   \n",
      "87499     AD-SECRRE  Hi Work 30 mins daily using your mobile phone ...   \n",
      "87500     JD-JIOINF  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...   \n",
      "87501     JD-JIOINF  IMPORTANT: Beware of the fraudulent messages a...   \n",
      "87502     AD-KJRIWL  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...   \n",
      "87503     JD-AKAMAH  As we celebrate Azadi Ka Amrit Mahotsav, let's...   \n",
      "\n",
      "      phoneNumber                      updateAt  \n",
      "0      xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "1      xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "2      xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "3      xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "4      xx39973810  Sat, 7 May 2022 19:48:00 UTC  \n",
      "...           ...                           ...  \n",
      "87499  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "87500  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "87501  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "87502  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "87503  xx86412509  Wed, 4 May 2022 07:14:44 UTC  \n",
      "\n",
      "[87491 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('filtered_data1.csv')\n",
    "\n",
    "# Drop rows where 'senderAddress' contains an alphanumeric pattern (letters and numbers together)\n",
    "df = df[~df['senderAddress'].str.match(r'.*\\d.*[A-Za-z].*', na=False)]\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(df)\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_filtered_data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816af777-9e9c-4842-9204-2caa4291547d",
   "metadata": {},
   "source": [
    "# Make a column of Debit and Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a507ad9a-4707-4317-b97a-381aa9c260e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text   transaction  \\\n",
      "0      Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...  Not Received   \n",
      "1      Hi! Update your email id through WhatsApp: htt...  Not Received   \n",
      "2      Lucknow ya Kolkata ? - watch it LIVE with Vi c...  Not Received   \n",
      "3      Mohd,\\nCheck the incredible Acko insurance pol...  Not Received   \n",
      "4      Hi! You can now get your Vi prepaid invoice em...  Not Received   \n",
      "...                                                  ...           ...   \n",
      "87486  Hi Work 30 mins daily using your mobile phone ...  Not Received   \n",
      "87487  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...  Not Received   \n",
      "87488  IMPORTANT: Beware of the fraudulent messages a...  Not Received   \n",
      "87489  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...  Not Received   \n",
      "87490  As we celebrate Azadi Ka Amrit Mahotsav, let's...  Not Received   \n",
      "\n",
      "      debit_account receiver  \n",
      "0              None     None  \n",
      "1              None     None  \n",
      "2              None     None  \n",
      "3              None     None  \n",
      "4              None     None  \n",
      "...             ...      ...  \n",
      "87486          None     None  \n",
      "87487          None     None  \n",
      "87488          None     None  \n",
      "87489          None     None  \n",
      "87490          None     None  \n",
      "\n",
      "[87491 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "  # Replace with your file path\n",
    "df = pd.read_csv('updated_filtered_data1.csv')\n",
    "\n",
    "# Define a function to categorize transactions and extract account info\n",
    "def categorize_transaction(message):\n",
    "    message = str(message).lower()  # Convert message to lowercase for case-insensitive comparison\n",
    "    debit_account = None\n",
    "    receiver = None\n",
    "\n",
    "    # Check for money credit and extract receiver details\n",
    "    credit_match = re.search(r'money credited to (\\S+)', message)\n",
    "    if credit_match:\n",
    "        receiver = credit_match.group(1)\n",
    "        return 'Money Credit', debit_account, receiver\n",
    "    \n",
    "    # Check for money debit and extract debit account details\n",
    "    debit_match = re.search(r'money debited from (\\S+)', message)\n",
    "    if debit_match:\n",
    "        debit_account = debit_match.group(1)\n",
    "        return 'Money Debit', debit_account, receiver\n",
    "    \n",
    "    return 'Not Received', debit_account, receiver\n",
    "\n",
    "# Apply the function to the 'text' column and create new columns\n",
    "df[['transaction', 'debit_account', 'receiver']] = df['text'].apply(lambda x: pd.Series(categorize_transaction(x)))\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(df[['text', 'transaction', 'debit_account', 'receiver']])\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_file_with_account_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cfa35-4cbe-4262-96a5-b824b0c3c528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4323a0-089e-44b0-8dc4-3389c9b3f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text   transaction  \\\n",
      "0      Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...  Not Received   \n",
      "1      Hi! Update your email id through WhatsApp: htt...  Not Received   \n",
      "2      Lucknow ya Kolkata ? - watch it LIVE with Vi c...  Not Received   \n",
      "3      Mohd,\\nCheck the incredible Acko insurance pol...  Not Received   \n",
      "4      Hi! You can now get your Vi prepaid invoice em...  Not Received   \n",
      "...                                                  ...           ...   \n",
      "87486  Hi Work 30 mins daily using your mobile phone ...  Not Received   \n",
      "87487  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...  Not Received   \n",
      "87488  IMPORTANT: Beware of the fraudulent messages a...  Not Received   \n",
      "87489  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...  Not Received   \n",
      "87490  As we celebrate Azadi Ka Amrit Mahotsav, let's...  Not Received   \n",
      "\n",
      "      debit_account receiver  \n",
      "0              None     None  \n",
      "1              None     None  \n",
      "2              None     None  \n",
      "3              None     None  \n",
      "4              None     None  \n",
      "...             ...      ...  \n",
      "87486          None     None  \n",
      "87487          None     None  \n",
      "87488          None     None  \n",
      "87489          None     None  \n",
      "87490          None     None  \n",
      "\n",
      "[87491 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('updated_filtered_data1.csv')\n",
    "\n",
    "# Define a function to categorize transactions and extract account info\n",
    "def categorize_transaction(message):\n",
    "    message = str(message).lower()  # Convert message to lowercase for case-insensitive comparison\n",
    "    debit_account = None\n",
    "    receiver = None\n",
    "\n",
    "    # Check for money credit and extract receiver details\n",
    "    credit_match = re.search(r'money credited to (\\S+)', message)\n",
    "    if credit_match:\n",
    "        receiver = credit_match.group(1)\n",
    "        return 'Money Credit', debit_account, receiver\n",
    "    \n",
    "    # Check for money debit and extract debit account details\n",
    "    debit_match = re.search(r'money debited from (\\S+)', message)\n",
    "    if debit_match:\n",
    "        debit_account = debit_match.group(1)\n",
    "        return 'Money Debit', debit_account, receiver\n",
    "    \n",
    "    return 'Not Received', debit_account, receiver\n",
    "\n",
    "# Apply the function to the 'text' column and create new columns\n",
    "df[['transaction', 'debit_account', 'receiver']] = df['text'].apply(lambda x: pd.Series(categorize_transaction(x)))\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(df[['text', 'transaction', 'debit_account', 'receiver']])\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_file_with_account_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85810215-a6c2-4710-a905-6e377f7264b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc89542-300a-4509-b323-17ea71b7ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text debit credit\n",
      "0      Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...  None   None\n",
      "1      Hi! Update your email id through WhatsApp: htt...  None   None\n",
      "2      Lucknow ya Kolkata ? - watch it LIVE with Vi c...  None   None\n",
      "3      Mohd,\\nCheck the incredible Acko insurance pol...  None   None\n",
      "4      Hi! You can now get your Vi prepaid invoice em...  None   None\n",
      "...                                                  ...   ...    ...\n",
      "87486  Hi Work 30 mins daily using your mobile phone ...  None   None\n",
      "87487  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...  None   None\n",
      "87488  IMPORTANT: Beware of the fraudulent messages a...  None   None\n",
      "87489  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...  None   None\n",
      "87490  As we celebrate Azadi Ka Amrit Mahotsav, let's...  None   None\n",
      "\n",
      "[87491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv('updated_filtered_data1.csv')\n",
    "\n",
    "# Define a function to extract debit and credit details\n",
    "def extract_debit_credit(message):\n",
    "    debit = None\n",
    "    credit = None\n",
    "\n",
    "    # Regular expression to extract debit details (account number and amount)\n",
    "    debit_match = re.search(r'a/c no\\.\\s([A-Za-z0-9]+).*?is debited for Rs\\.(\\d+\\.\\d{2})', message)\n",
    "    if debit_match:\n",
    "        debit = f\"a/c no. {debit_match.group(1)} is debited Rs.{debit_match.group(2)}\"\n",
    "    \n",
    "    # Regular expression to extract credit details (account and amount)\n",
    "    credit_match = re.search(r'credited to\\s([A-Za-z0-9@.]+).*Rs\\.(\\d+\\.\\d{2})', message)\n",
    "    if credit_match:\n",
    "        credit = f\"credited to {credit_match.group(1)} Rs.{credit_match.group(2)}\"\n",
    "    \n",
    "    # If neither debit nor credit found, set both as 'None'\n",
    "    if not debit and not credit:\n",
    "        debit = 'None'\n",
    "        credit = 'None'\n",
    "    \n",
    "    return pd.Series([debit, credit])\n",
    "\n",
    "# Apply the function to the 'text' column and create new columns for debit and credit\n",
    "df[['debit', 'credit']] = df['text'].apply(lambda x: extract_debit_credit(x))\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(df[['text', 'debit', 'credit']])\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_file_with_debit_credit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15adbda-0d2b-44c0-ab09-410841e39114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text debit credit\n",
      "0      Rs.95.15 on Zomato charged via Simpl.\\r\\n--\\r\\...  None   None\n",
      "1      Hi! Update your email id through WhatsApp: htt...  None   None\n",
      "2      Lucknow ya Kolkata ? - watch it LIVE with Vi c...  None   None\n",
      "3      Mohd,\\nCheck the incredible Acko insurance pol...  None   None\n",
      "4      Hi! You can now get your Vi prepaid invoice em...  None   None\n",
      "...                                                  ...   ...    ...\n",
      "87486  Hi Work 30 mins daily using your mobile phone ...  None   None\n",
      "87487  ਜ਼ਰੂਰੀ  ਸੂਚਨਾ: ਅਜਿਹੇ ਕਿਸੇ ਵੀ ਧੋਖਾਧੜੀ ਵਾਲੇ ਮੈਸੇਜ...  None   None\n",
      "87488  IMPORTANT: Beware of the fraudulent messages a...  None   None\n",
      "87489  ਵਧਾਈਆਂ!\\nਕੇਜਰੀਵਾਲ ਜੀ ਦੀ ਮੁਫ਼ਤ ਬਿਜਲੀ ਗਰੰਟੀ ਲਈ ਤ...  None   None\n",
      "87490  As we celebrate Azadi Ka Amrit Mahotsav, let's...  None   None\n",
      "\n",
      "[87491 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your CSV file\n",
    "  # Replace with your file path\n",
    "df = pd.read_csv('updated_filtered_data1.csv')\n",
    "\n",
    "# Define a function to extract debit and credit details\n",
    "def extract_debit_credit(message):\n",
    "    debit = None\n",
    "    credit = None\n",
    "\n",
    "    # Regular expression to extract debit details (account number and amount)\n",
    "    debit_match = re.search(r'a/c no\\.\\s([A-Za-z0-9]+).*?is debited for Rs\\.(\\d+\\.\\d{2})', message)\n",
    "    if debit_match:\n",
    "        debit = f\"a/c no. {debit_match.group(1)} is debited Rs.{debit_match.group(2)}\"\n",
    "    \n",
    "    # Regular expression to extract credit details (account and amount)\n",
    "    credit_match = re.search(r'credited to\\s([A-Za-z0-9@.]+).*Rs\\.(\\d+\\.\\d{2})', message)\n",
    "    if credit_match:\n",
    "        credit = f\"credited to {credit_match.group(1)} Rs.{credit_match.group(2)}\"\n",
    "    \n",
    "    # If neither debit nor credit found, set both as 'None'\n",
    "    if not debit and not credit:\n",
    "        debit = 'None'\n",
    "        credit = 'None'\n",
    "    \n",
    "    return pd.Series([debit, credit])\n",
    "\n",
    "# Apply the function to the 'text' column and create new columns for debit and credit\n",
    "df[['debit', 'credit']] = df['text'].apply(lambda x: extract_debit_credit(x))\n",
    "\n",
    "# Print the updated DataFrame (optional)\n",
    "print(df[['text', 'debit', 'credit']])\n",
    "\n",
    "# Optionally, save the updated DataFrame to a new CSV file\n",
    "df.to_csv('updated_file_with_debit_credit1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cfc072-a0d2-42ed-9eb1-8da829f4a5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      debit  amount_debit\n",
      "0       NaN           NaN\n",
      "1       NaN           NaN\n",
      "2       NaN           NaN\n",
      "3       NaN           NaN\n",
      "4       NaN           NaN\n",
      "...     ...           ...\n",
      "87486   NaN           NaN\n",
      "87487   NaN           NaN\n",
      "87488   NaN           NaN\n",
      "87489   NaN           NaN\n",
      "87490   NaN           NaN\n",
      "\n",
      "[87491 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_file_with_debit_credit1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define a function to extract the debit amount from the debit string\n",
    "def extract_debit_amount(debit_string):\n",
    "    # Regular expression to extract the amount after 'Rs.'\n",
    "    match = re.search(r'Rs\\.(\\d+\\.\\d{2})', str(debit_string))  # Ensure it is treated as a string\n",
    "    if match:\n",
    "        return float(match.group(1))  # Return the extracted amount as a float\n",
    "    else:\n",
    "        return None  # Return None if no amount is found\n",
    "\n",
    "# Apply the function to the 'debit' column to extract the amounts\n",
    "df['amount_debit'] = df['debit'].apply(extract_debit_amount)\n",
    "\n",
    "# Print the DataFrame with the new 'amount_debit' column\n",
    "print(df[['debit', 'amount_debit']])\n",
    "\n",
    "# Optionally, save the updated DataFrame with extracted amounts to a new CSV file\n",
    "df.to_csv('updated_file_with_amount_debit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def24eb5-60a7-4907-840c-6edf098e8dd5",
   "metadata": {},
   "source": [
    "#  Debited Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c108332f-775a-4a6d-9d03-f567c1e2dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\3764936370.py:26: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df.to_csv('D:\\debit.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Debit Amount: Rs. 392483.03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_file_with_debit_credit1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define a function to extract the debit amount from the debit string\n",
    "def extract_debit_amount(debit_string):\n",
    "    # Regular expression to extract the amount after 'Rs.'\n",
    "    match = re.search(r'Rs\\.(\\d+\\.\\d{2})', str(debit_string))  # Ensure it is treated as a string\n",
    "    if match:\n",
    "        return float(match.group(1))  # Return the extracted amount as a float\n",
    "    else:\n",
    "        return None  # Return None if no amount is found\n",
    "\n",
    "# Apply the function to the 'debit' column to extract the amounts\n",
    "df['amount_debit'] = df['debit'].apply(extract_debit_amount)\n",
    "\n",
    "# Calculate the sum of the 'amount_debit' column\n",
    "total_debit_sum = df['amount_debit'].sum()\n",
    "\n",
    "# Print the total debit sum\n",
    "print(f\"Total Debit Amount: Rs. {total_debit_sum:.2f}\")\n",
    "\n",
    "# Optionally, save the updated DataFrame with extracted amounts to a new CSV file\n",
    "df.to_csv('D:\\debit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e883d-8f05-476a-ae33-f872922d0d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f30e899d-c1c8-4607-ad8a-170ad9392e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      senderAddress                                               text\n",
      "3603      JX-JIOPAY  Recharge of Rs. 50.0 is successful for your Ji...\n",
      "11767     JG-JioPay  26-Feb-22 19:59 પર 100% ડેટા કોટા સમાપ્ત થઈ ગય...\n",
      "11768     JG-JioPay  100% data quota exhausted as on 26-Feb-22 19:5...\n",
      "11769     JG-JioPay  26-Feb-22 17:59 કલાકે 90% ડેટા ક્વોટા ઉપયોગમાં...\n",
      "11770     JG-JioPay  90% Data quota used as on 26-Feb-22 17:59.\\nJi...\n",
      "11782     JG-JioPay  25-Feb-22 22:57 કલાકે 50% ડેટા ક્વોટા ઉપયોગમાં...\n",
      "11783     JG-JioPay  50% Data quota used as on 25-Feb-22 22:57.\\nJi...\n",
      "11807     JG-JioPay  23-Feb-22 01:22 પર 100% ડેટા કોટા સમાપ્ત થઈ ગય...\n",
      "11808     JG-JioPay  100% data quota exhausted as on 23-Feb-22 01:2...\n",
      "11809     JG-JioPay  22-Feb-22 23:19 કલાકે 90% ડેટા ક્વોટા ઉપયોગમાં...\n",
      "11810     JG-JioPay  90% Data quota used as on 22-Feb-22 23:19.\\nJi...\n",
      "11825     JG-JioPay  21-Feb-22 22:22 કલાકે 50% ડેટા ક્વોટા ઉપયોગમાં...\n",
      "11826     JG-JioPay  50% Data quota used as on 21-Feb-22 22:22.\\nJi...\n",
      "11851     JG-JioPay  19-Feb-22 21:06 પર 100% ડેટા કોટા સમાપ્ત થઈ ગય...\n",
      "11852     JG-JioPay  100% data quota exhausted as on 19-Feb-22 21:0...\n",
      "11856     JG-JioPay  19-Feb-22 19:25 કલાકે 90% ડેટા ક્વોટા ઉપયોગમાં...\n",
      "11857     JG-JioPay  90% Data quota used as on 19-Feb-22 19:25.\\nJi...\n",
      "26899     JX-JIOPAY  Recharge of Rs. 50.0 is successful for your Ji...\n",
      "36961     JY-JioPay  08-Jan-22 18:25 बजे तक 100% डेटा कोटा खर्च हो ...\n",
      "36962     JY-JioPay  100% data quota exhausted as on 08-Jan-22 18:2...\n",
      "36964     JY-JioPay  08-Jan-22 17:30 बजे तक 90% डेटा कोटा खर्च हो च...\n",
      "36965     JY-JioPay  90% Data quota used as on 08-Jan-22 17:30.\\nJi...\n",
      "36983     JY-JioPay  07-Jan-22 22:50 बजे तक 50% डेटा कोटा खर्च हो च...\n",
      "36984     JY-JioPay  50% Data quota used as on 07-Jan-22 22:50.\\nJi...\n",
      "38809     JY-JioPay  08-Jan-22 18:25 बजे तक 100% डेटा कोटा खर्च हो ...\n",
      "38810     JY-JioPay  100% data quota exhausted as on 08-Jan-22 18:2...\n",
      "38812     JY-JioPay  08-Jan-22 17:30 बजे तक 90% डेटा कोटा खर्च हो च...\n",
      "38813     JY-JioPay  90% Data quota used as on 08-Jan-22 17:30.\\nJi...\n",
      "38831     JY-JioPay  07-Jan-22 22:50 बजे तक 50% डेटा कोटा खर्च हो च...\n",
      "38832     JY-JioPay  50% Data quota used as on 07-Jan-22 22:50.\\nJi...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_file_with_debit_credit1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Function to check if the sender address contains 'jiopay' and text contains 'Rs', 'credit', or 'debit'\n",
    "def filter_messages(row):\n",
    "    # Check if 'jiopay' is in senderAddress (case insensitive) and text contains 'Rs', 'credit', or 'debit'\n",
    "    if 'jiopay' in str(row['senderAddress']).lower() and re.search(r'(Rs|credit|debit)', str(row['text']).lower()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Apply the filter to the dataframe\n",
    "filtered_df = df[df.apply(filter_messages, axis=1)]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(filtered_df[['senderAddress', 'text']])\n",
    "\n",
    "# Optionally, save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv('filtered_jiopay_messages1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c25d63-32a0-493a-9851-7d0af53578f8",
   "metadata": {},
   "source": [
    "# credit amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4c60c058-1ed8-4c0d-843e-4a7631e621e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\4280198182.py:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df.to_csv('D:\\credit1.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Credit Amount: Rs. 1348243.42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define a function to extract credited information from the 'text' column\n",
    "def extract_credit_info(text_string):\n",
    "    # Search for 'credit' or 'received' and extract the information after it\n",
    "    credit_match = re.search(r'(credit|received)[^\\d]*(\\d+\\.\\d{2})', str(text_string).lower())\n",
    "    if credit_match:\n",
    "        # Extract the credited account or amount after 'credit' or 'received'\n",
    "        amount = credit_match.group(2)\n",
    "        return f\"credited Rs.{amount}\"  # Return the formatted credit information\n",
    "    else:\n",
    "        return None  # If no match is found, return None\n",
    "\n",
    "# Apply the function to the 'text' column to extract credited information\n",
    "df['credit'] = df['text'].apply(extract_credit_info)\n",
    "\n",
    "# Function to extract the numeric value from the credit column\n",
    "def extract_credit_amount(credit_string):\n",
    "    # Use regex to find the amount in the 'credit' column formatted as 'credited Rs.<amount>'\n",
    "    match = re.search(r'Rs\\.(\\d+\\.\\d{2})', str(credit_string))\n",
    "    if match:\n",
    "        return float(match.group(1))  # Return the amount as a float\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no amount is found\n",
    "\n",
    "# Apply the function to the 'credit' column to extract the numeric amounts\n",
    "df['credit_amount'] = df['credit'].apply(extract_credit_amount)\n",
    "\n",
    "# Calculate the sum of the amounts in the 'credit_amount' column\n",
    "total_credit_amount = df['credit_amount'].sum()\n",
    "\n",
    "# Print the total credit amount\n",
    "print(f\"Total Credit Amount: Rs. {total_credit_amount:.2f}\")\n",
    "\n",
    "# Optionally, save the updated DataFrame with extracted credit amounts to a new CSV file\n",
    "df.to_csv('D:\\credit1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbd65a-64fb-4f9e-99b9-76003f05e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Credit Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4eebda-d318-44fb-bcdf-81e33dade786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5155b3d8-c33c-402b-a22e-9a640b1589f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\943779614.py:40: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df.to_csv('D:\\credit.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Credit Amount: Rs. 1369924.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define a function to extract credited information from the 'text' column\n",
    "def extract_credit_info(text_string):\n",
    "    # Search for 'credit', 'received', or 'deposit' and extract the information after it\n",
    "    credit_match = re.search(r'(credit|received|deposit)[^\\d]*(\\d+\\.\\d{2})', str(text_string).lower())\n",
    "    if credit_match:\n",
    "        # Extract the credited amount after 'credit', 'received', or 'deposit'\n",
    "        amount = credit_match.group(2)\n",
    "        return f\"credited Rs.{amount}\"  # Return the formatted credit information\n",
    "    else:\n",
    "        return None  # If no match is found, return None\n",
    "\n",
    "# Apply the function to the 'text' column to extract credited information\n",
    "df['credit'] = df['text'].apply(extract_credit_info)\n",
    "\n",
    "# Function to extract the numeric value from the credit column\n",
    "def extract_credit_amount(credit_string):\n",
    "    # Use regex to find the amount in the 'credit' column formatted as 'credited Rs.<amount>'\n",
    "    match = re.search(r'Rs\\.(\\d+\\.\\d{2})', str(credit_string))\n",
    "    if match:\n",
    "        return float(match.group(1))  # Return the amount as a float\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no amount is found\n",
    "\n",
    "# Apply the function to the 'credit' column to extract the numeric amounts\n",
    "df['credit_amount'] = df['credit'].apply(extract_credit_amount)\n",
    "\n",
    "# Calculate the sum of the amounts in the 'credit_amount' column\n",
    "total_credit_amount = df['credit_amount'].sum()\n",
    "\n",
    "# Print the total credit amount\n",
    "print(f\"Total Credit Amount: Rs. {total_credit_amount:.2f}\")\n",
    "\n",
    "# Optionally, save the updated DataFrame with extracted credit amounts to a new CSV file\n",
    "df.to_csv('D:\\credit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c54fc-813b-4e95-a55b-e2596f747329",
   "metadata": {},
   "source": [
    "# Transaction done by Paytm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93734be6-db30-424a-95d3-c8346d31c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      senderAddress                                               text\n",
      "8         AX-PAYTMB  Received Rs.600.00 in your a/c 91XX3635 from O...\n",
      "9         BP-iPaytm  Count#1: Rs 600 paid by 98XXXX4000 at 12:20 AM...\n",
      "28        AX-iPaytm  Paytm login detected from a new device at 03:1...\n",
      "29        AD-iPaytm  Paytm For Business login requested from a new ...\n",
      "30        AX-iPaytm  <#>Paytm never calls for OTP. Do not share it ...\n",
      "...             ...                                                ...\n",
      "85009     BP-PAYTMB  UPI registration for your Paytm App has begun....\n",
      "85076     BP-PAYTMB  PPBL savings a/c 919290427762 is blocked for i...\n",
      "85140     BP-PAYTMB  Your Paytm Bank Savings A/C 919290427762 will ...\n",
      "85304     BP-PAYTMB  You have successfully set UPI PIN for your Pay...\n",
      "85328     AX-iPaytm  Paytm login detected from a new device at 07:3...\n",
      "\n",
      "[1473 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Filter rows where 'senderAddress' column contains the word 'paytm'\n",
    "filtered_rows = df[df['senderAddress'].str.contains('paytm', case=False, na=False)]\n",
    "\n",
    "# Print only the 'senderAddress' and 'text' columns for the filtered rows\n",
    "print(filtered_rows[['senderAddress', 'text']])\n",
    "\n",
    "# Optionally, save the filtered rows to a new CSV file\n",
    "filtered_rows.to_csv('paytm_filtered_rows.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73016e6-8dca-4c05-b596-59e6b6e53a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fe20508-448a-4c26-a494-eb3dd09363e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      senderAddress\n",
      "8         AX-PAYTMB\n",
      "9         BP-iPaytm\n",
      "28        AX-iPaytm\n",
      "29        AD-iPaytm\n",
      "30        AX-iPaytm\n",
      "...             ...\n",
      "85009     BP-PAYTMB\n",
      "85076     BP-PAYTMB\n",
      "85140     BP-PAYTMB\n",
      "85304     BP-PAYTMB\n",
      "85328     AX-iPaytm\n",
      "\n",
      "[1473 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('updated_filtered_data1.csv')\n",
    "\n",
    "\n",
    "# Filter rows where 'senderAddress' column contains the word 'paytm'\n",
    "filtered_rows = df[df['senderAddress'].str.contains('paytm', case=False, na=False)]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(filtered_rows[['senderAddress']])\n",
    "\n",
    "# Optionally, save the filtered rows to a new CSV file\n",
    "filtered_rows.to_csv('paytm_filtered_rows12.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a647-2630-46fb-95c9-941d0a514a1b",
   "metadata": {},
   "source": [
    "#  Total Money Pay By paytm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7f6af9fd-8dae-46e1-b4d7-3c250b1dbba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:28: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\1379280824.py:28: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  result_with_money.to_csv('D:\\paytm_with_money.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Money: Rs. 251551.16\n",
      "Filtered data has been saved to 'paytm_with_money.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "filtered_rows = pd.read_csv('updated_filtered_data1.csv')  # Replace with the actual file path\n",
    "\n",
    "# Define a function to extract the amount associated with the words \"sent\" or \"paid\" in the 'text' column\n",
    "def extract_money_from_text(text):\n",
    "    # Search for the pattern \"sent Rs.<amount>\" or \"paid Rs.<amount>\"\n",
    "    match = re.search(r'(sent|paid)[^\\d]*(\\d+\\.\\d{2})', str(text).lower())\n",
    "    if match:\n",
    "        return float(match.group(2))  # Return the amount as a float\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a new 'money' column\n",
    "filtered_rows['money'] = filtered_rows['text'].apply(extract_money_from_text)\n",
    "\n",
    "# Filter rows where 'money' column is not null\n",
    "result_with_money = filtered_rows[filtered_rows['money'].notnull()]\n",
    "\n",
    "# Calculate the sum of the money column\n",
    "total_money = result_with_money['money'].sum()\n",
    "\n",
    "# Print the total sum of money\n",
    "print(f\"Total Money: Rs. {total_money:.2f}\")\n",
    "\n",
    "# Save the resulting DataFrame with the new 'money' column to a CSV file\n",
    "result_with_money.to_csv('D:\\paytm_with_money.csv', index=False)\n",
    "\n",
    "print(\"Filtered data has been saved to 'paytm_with_money.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "729fc23d-ad5a-4615-b438-e1bca57f6c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to 'filtered_sender_keywords.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define the list of keywords to search for in the 'senderAddress' column\n",
    "keywords = ['bnk', 'BNK', 'kotak', 'sbi', 'icici']\n",
    "\n",
    "# Filter rows where 'senderAddress' contains any of the keywords (case-insensitive)\n",
    "filtered_rows = df[df['senderAddress'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Save the filtered rows to a new CSV file\n",
    "filtered_rows.to_csv('filtered_sender_keywords.csv', index=False)\n",
    "\n",
    "print(\"Filtered data has been saved to 'filtered_sender_keywords.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ddf78e01-fa0b-44b5-bf88-fe496ec51485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87491, 4)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c2b82-9080-4fd2-8d51-bb391f38eb0c",
   "metadata": {},
   "source": [
    "# Statement of all  bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b352b54-28c3-4883-968e-c675d5e24978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   senderAddress                                               text  \\\n",
      "45     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "50     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "51     VK-IndBnk  Your VPA 6280368198@paytm linked to Indian Ban...   \n",
      "61     VK-IndBnk  Your VPA 6280368198@ybl linked to Indian Bank ...   \n",
      "64     VK-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "\n",
      "   phoneNumber                      updateAt  amount  \n",
      "45  xx80368198  Tue, 3 May 2022 08:53:39 UTC    39.0  \n",
      "50  xx80368198  Tue, 3 May 2022 08:53:39 UTC    39.0  \n",
      "51  xx80368198  Tue, 3 May 2022 08:53:39 UTC   628.0  \n",
      "61  xx80368198  Tue, 3 May 2022 08:53:39 UTC   628.0  \n",
      "64  xx80368198  Tue, 3 May 2022 08:53:39 UTC    39.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\214875510.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['amount'] = transaction_rows['text'].apply(extract_amount)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define the list of keywords to search for in the 'senderAddress' column\n",
    "keywords = ['bnk', 'BNK', 'kotak', 'sbi', 'icici']\n",
    "\n",
    "# Filter rows where 'senderAddress' contains any of the keywords (case-insensitive)\n",
    "filtered_rows = df[df['senderAddress'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Further filter rows where the 'text' column contains transaction-related keywords\n",
    "transaction_keywords = ['debited', 'credited', 'paid', 'transfer', 'sent']\n",
    "transaction_rows = filtered_rows[filtered_rows['text'].str.contains('|'.join(transaction_keywords), case=False, na=False)]\n",
    "\n",
    "# Function to extract amount (assuming amounts are numbers with or without commas and decimals)\n",
    "def extract_amount(text):\n",
    "    match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts like 1,000.00 or 1000.00\n",
    "    if match:\n",
    "        return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts from the 'text' column\n",
    "transaction_rows['amount'] = transaction_rows['text'].apply(extract_amount)\n",
    "\n",
    "# Save the filtered transaction statements with the amount to a new CSV file\n",
    "transaction_rows.to_csv('transaction_statements_with_amount.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(transaction_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d0ed1c93-c1e7-4a5d-9a14-09a4280a3549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8949, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c36645bc-6111-42d8-88f0-e356ce79ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:33: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\1529711193.py:33: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  transaction_rows.to_csv('D:\\ bankamounts.csv', index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   senderAddress                                               text  \\\n",
      "45     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "50     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "51     VK-IndBnk  Your VPA 6280368198@paytm linked to Indian Ban...   \n",
      "61     VK-IndBnk  Your VPA 6280368198@ybl linked to Indian Bank ...   \n",
      "64     VK-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "\n",
      "   phoneNumber                      updateAt  debited_amount  credited_amount  \n",
      "45  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0  \n",
      "50  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0  \n",
      "51  xx80368198  Tue, 3 May 2022 08:53:39 UTC          -628.0            628.0  \n",
      "61  xx80368198  Tue, 3 May 2022 08:53:39 UTC          -628.0            628.0  \n",
      "64  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\1529711193.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\1529711193.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define the list of keywords to search for in the 'senderAddress' column\n",
    "keywords = ['bnk', 'BNK', 'kotak', 'sbi', 'icici']\n",
    "\n",
    "# Filter rows where 'senderAddress' contains any of the keywords (case-insensitive)\n",
    "filtered_rows = df[df['senderAddress'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Further filter rows where the 'text' column contains transaction-related keywords\n",
    "transaction_keywords = ['debited', 'credited', 'paid', 'transfer', 'sent']\n",
    "transaction_rows = filtered_rows[filtered_rows['text'].str.contains('|'.join(transaction_keywords), case=False, na=False)]\n",
    "\n",
    "# Function to extract amount based on debit or credit\n",
    "def extract_amount(text, transaction_type):\n",
    "    match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts like 1,000.00 or 1000.00\n",
    "    if match:\n",
    "        amount = float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "        if transaction_type == 'debited':\n",
    "            return -amount  # Debit amounts are negative\n",
    "        elif transaction_type == 'credited':\n",
    "            return amount  # Credit amounts are positive\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts and separate them into credit and debit columns\n",
    "transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
    "transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n",
    "\n",
    "# Save the filtered transaction statements with the amount to a new CSV file\n",
    "transaction_rows.to_csv('D:\\ bankamounts.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(transaction_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5d4ade3-ff4e-4ba2-a903-248947ef1d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Debited Amount: -1391559.6800000002\n",
      "Total Credited Amount: 1388764.86\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of debited and credited amounts\n",
    "total_debited = transaction_rows['debited_amount'].sum()  # Sum of debited amounts\n",
    "total_credited = transaction_rows['credited_amount'].sum()  # Sum of credited amounts\n",
    "\n",
    "# Display the total sums\n",
    "print(f\"Total Debited Amount: {total_debited}\")\n",
    "print(f\"Total Credited Amount: {total_credited}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2f3fb9bc-998d-4ea8-b95e-4c0f5b67750e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Debited Amount: -1391559.6800000002\n",
      "Total Credited Amount: 1388764.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['NEFT'] = transaction_rows['text'].apply(extract_neft_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Plaza'] = transaction_rows['text'].apply(extract_plaza_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['deposit'] = transaction_rows['text'].apply(extract_deposit_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Dream11'] = transaction_rows['text'].apply(extract_dream11_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2534679057.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Zomato'] = transaction_rows['text'].apply(extract_zomato_amount)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\x07ll columns.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[204], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Credited Amount: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_credited\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Save the filtered transaction statements with the 'NEFT', 'Plaza', 'deposit', 'Dream11', and 'Zomato' columns to a new CSV file\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m transaction_rows\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mll columns.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(transaction_rows\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\x07ll columns.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define the list of keywords to search for in the 'senderAddress' column\n",
    "keywords = ['bnk', 'BNK', 'kotak', 'sbi', 'icici']\n",
    "\n",
    "# Filter rows where 'senderAddress' contains any of the keywords (case-insensitive)\n",
    "filtered_rows = df[df['senderAddress'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Further filter rows where the 'text' column contains transaction-related keywords\n",
    "transaction_keywords = ['debited', 'credited', 'paid', 'transfer', 'sent']\n",
    "transaction_rows = filtered_rows[filtered_rows['text'].str.contains('|'.join(transaction_keywords), case=False, na=False)]\n",
    "\n",
    "# Function to extract amount based on debit or credit\n",
    "def extract_amount(text, transaction_type):\n",
    "    match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts like 1,000.00 or 1000.00\n",
    "    if match:\n",
    "        amount = float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "        if transaction_type == 'debited':\n",
    "            return -amount  # Debit amounts are negative\n",
    "        elif transaction_type == 'credited':\n",
    "            return amount  # Credit amounts are positive\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts and separate them into credit and debit columns\n",
    "transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
    "transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n",
    "\n",
    "# Function to extract amount when the word 'NEFT' is present in the 'text'\n",
    "def extract_neft_amount(text):\n",
    "    if 'NEFT' in text:  # Check if 'NEFT' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Plaza' is present in the 'text'\n",
    "def extract_plaza_amount(text):\n",
    "    if 'Plaza' in text:  # Check if 'Plaza' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'deposit' is present in the 'text'\n",
    "def extract_deposit_amount(text):\n",
    "    if 'deposit' in text:  # Check if 'deposit' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Dream11' is present in the 'text'\n",
    "def extract_dream11_amount(text):\n",
    "    if 'Dream11' in text:  # Check if 'Dream11' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Zomato' is present in the 'text'\n",
    "def extract_zomato_amount(text):\n",
    "    if 'Zomato' in text:  # Check if 'Zomato' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts for the 'NEFT', 'Plaza', 'deposit', 'Dream11', and 'Zomato' columns\n",
    "transaction_rows['NEFT'] = transaction_rows['text'].apply(extract_neft_amount)\n",
    "transaction_rows['Plaza'] = transaction_rows['text'].apply(extract_plaza_amount)\n",
    "transaction_rows['deposit'] = transaction_rows['text'].apply(extract_deposit_amount)\n",
    "transaction_rows['Dream11'] = transaction_rows['text'].apply(extract_dream11_amount)\n",
    "transaction_rows['Zomato'] = transaction_rows['text'].apply(extract_zomato_amount)\n",
    "\n",
    "# Calculate the sum of debited and credited amounts\n",
    "total_debited = transaction_rows['debited_amount'].sum()  # Sum of debited amounts\n",
    "total_credited = transaction_rows['credited_amount'].sum()  # Sum of credited amounts\n",
    "\n",
    "# Display the total sums\n",
    "print(f\"Total Debited Amount: {total_debited}\")\n",
    "print(f\"Total Credited Amount: {total_credited}\")\n",
    "\n",
    "# Save the filtered transaction statements with the 'NEFT', 'Plaza', 'deposit', 'Dream11', and 'Zomato' columns to a new CSV file\n",
    "transaction_rows.to_csv('D:\\all columns.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(transaction_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "93236a09-4405-4406-86f8-830746439b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Debited Amount: -1391559.6800000002\n",
      "Total Credited Amount: 1388764.86\n",
      "Total NEFT Amount: 130710.91\n",
      "Total Plaza Amount: 978.0\n",
      "Total Deposit Amount: 33940.0\n",
      "Total Dream11 Amount: 1510.0\n",
      "Total Zomato Amount: 5145.0\n",
      "Total Swiggy Amount: 0\n",
      "Total Others Amount: 2719594.47\n",
      "   senderAddress                                               text  \\\n",
      "45     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "50     VM-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "51     VK-IndBnk  Your VPA 6280368198@paytm linked to Indian Ban...   \n",
      "61     VK-IndBnk  Your VPA 6280368198@ybl linked to Indian Bank ...   \n",
      "64     VK-IndBnk  Your VPA sanju39chd@okaxis linked to Indian Ba...   \n",
      "\n",
      "   phoneNumber                      updateAt  debited_amount  credited_amount  \\\n",
      "45  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0   \n",
      "50  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0   \n",
      "51  xx80368198  Tue, 3 May 2022 08:53:39 UTC          -628.0            628.0   \n",
      "61  xx80368198  Tue, 3 May 2022 08:53:39 UTC          -628.0            628.0   \n",
      "64  xx80368198  Tue, 3 May 2022 08:53:39 UTC           -39.0             39.0   \n",
      "\n",
      "    NEFT  Plaza  deposit  Dream11  Zomato Swiggy  Others  \n",
      "45   NaN    NaN      NaN      NaN     NaN   None    39.0  \n",
      "50   NaN    NaN      NaN      NaN     NaN   None    39.0  \n",
      "51   NaN    NaN      NaN      NaN     NaN   None   628.0  \n",
      "61   NaN    NaN      NaN      NaN     NaN   None   628.0  \n",
      "64   NaN    NaN      NaN      NaN     NaN   None    39.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['NEFT'] = transaction_rows['text'].apply(extract_neft_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Plaza'] = transaction_rows['text'].apply(extract_plaza_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['deposit'] = transaction_rows['text'].apply(extract_deposit_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Dream11'] = transaction_rows['text'].apply(extract_dream11_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Zomato'] = transaction_rows['text'].apply(extract_zomato_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Swiggy'] = transaction_rows['text'].apply(extract_swiggy_amount)\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\261511457.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transaction_rows['Others'] = transaction_rows['text'].apply(extract_others)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('updated_filtered_data1.csv')  # Replace with your actual file path\n",
    "\n",
    "# Define the list of keywords to search for in the 'senderAddress' column\n",
    "keywords = ['bnk', 'BNK', 'kotak', 'sbi', 'icici']\n",
    "\n",
    "# Filter rows where 'senderAddress' contains any of the keywords (case-insensitive)\n",
    "filtered_rows = df[df['senderAddress'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Further filter rows where the 'text' column contains transaction-related keywords\n",
    "transaction_keywords = ['debited', 'credited', 'paid', 'transfer', 'sent']\n",
    "transaction_rows = filtered_rows[filtered_rows['text'].str.contains('|'.join(transaction_keywords), case=False, na=False)]\n",
    "\n",
    "# Function to extract amount based on debit or credit\n",
    "def extract_amount(text, transaction_type):\n",
    "    match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts like 1,000.00 or 1000.00\n",
    "    if match:\n",
    "        amount = float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "        if transaction_type == 'debited':\n",
    "            return -amount  # Debit amounts are negative\n",
    "        elif transaction_type == 'credited':\n",
    "            return amount  # Credit amounts are positive\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts and separate them into credit and debit columns\n",
    "transaction_rows['debited_amount'] = transaction_rows[transaction_rows['text'].str.contains('debited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'debited'))\n",
    "transaction_rows['credited_amount'] = transaction_rows[transaction_rows['text'].str.contains('credited', case=False, na=False)]['text'].apply(lambda x: extract_amount(x, 'credited'))\n",
    "\n",
    "# Function to extract amount when the word 'NEFT' is present in the 'text'\n",
    "def extract_neft_amount(text):\n",
    "    if 'NEFT' in text:  # Check if 'NEFT' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Plaza' is present in the 'text'\n",
    "def extract_plaza_amount(text):\n",
    "    if 'Plaza' in text:  # Check if 'Plaza' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'deposit' is present in the 'text'\n",
    "def extract_deposit_amount(text):\n",
    "    if 'deposit' in text.lower():  # Convert the text to lowercase to check for 'deposit'\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Dream11' is present in the 'text'\n",
    "def extract_dream11_amount(text):\n",
    "    if 'Dream11' in text:  # Check if 'Dream11' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Zomato' is present in the 'text'\n",
    "def extract_zomato_amount(text):\n",
    "    if 'Zomato' in text:  # Check if 'Zomato' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to extract amount when the word 'Swiggy' is present in the 'text'\n",
    "def extract_swiggy_amount(text):\n",
    "    if 'Swiggy' in text:  # Check if 'Swiggy' is in the text\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Remove commas if any and convert to float\n",
    "    return None\n",
    "\n",
    "# Function to check if no keyword is found and label it as \"Others\"\n",
    "def extract_others(text):\n",
    "    if not any(keyword in text for keyword in ['NEFT', 'Plaza', 'deposit', 'Dream11', 'Zomato', 'Swiggy']):\n",
    "        match = re.search(r'\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?', text)  # Match currency amounts\n",
    "        if match:\n",
    "            return float(match.group(0).replace(',', ''))  # Return amount if no keyword matched\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts for the 'NEFT', 'Plaza', 'deposit', 'Dream11', 'Zomato', 'Swiggy' and others columns\n",
    "transaction_rows['NEFT'] = transaction_rows['text'].apply(extract_neft_amount)\n",
    "transaction_rows['Plaza'] = transaction_rows['text'].apply(extract_plaza_amount)\n",
    "transaction_rows['deposit'] = transaction_rows['text'].apply(extract_deposit_amount)\n",
    "transaction_rows['Dream11'] = transaction_rows['text'].apply(extract_dream11_amount)\n",
    "transaction_rows['Zomato'] = transaction_rows['text'].apply(extract_zomato_amount)\n",
    "transaction_rows['Swiggy'] = transaction_rows['text'].apply(extract_swiggy_amount)\n",
    "transaction_rows['Others'] = transaction_rows['text'].apply(extract_others)\n",
    "\n",
    "# Calculate the sum of debited and credited amounts\n",
    "total_debited = transaction_rows['debited_amount'].sum()  # Sum of debited amounts\n",
    "total_credited = transaction_rows['credited_amount'].sum()  # Sum of credited amounts\n",
    "\n",
    "# Calculate the sum of the new columns\n",
    "total_neft = transaction_rows['NEFT'].sum()\n",
    "total_plaza = transaction_rows['Plaza'].sum()\n",
    "total_deposit = transaction_rows['deposit'].sum()\n",
    "total_dream11 = transaction_rows['Dream11'].sum()\n",
    "total_zomato = transaction_rows['Zomato'].sum()\n",
    "total_swiggy = transaction_rows['Swiggy'].sum()\n",
    "total_others = transaction_rows['Others'].sum()\n",
    "\n",
    "# Display the total sums\n",
    "print(f\"Total Debited Amount: {total_debited}\")\n",
    "print(f\"Total Credited Amount: {total_credited}\")\n",
    "print(f\"Total NEFT Amount: {total_neft}\")\n",
    "print(f\"Total Plaza Amount: {total_plaza}\")\n",
    "print(f\"Total Deposit Amount: {total_deposit}\")\n",
    "print(f\"Total Dream11 Amount: {total_dream11}\")\n",
    "print(f\"Total Zomato Amount: {total_zomato}\")\n",
    "print(f\"Total Swiggy Amount: {total_swiggy}\")\n",
    "print(f\"Total Others Amount: {total_others}\")\n",
    "\n",
    "# Save the filtered transaction statements with the new columns to a new CSV file\n",
    "transaction_rows.to_csv('D:/all_amount.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(transaction_rows.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345db9f-acd6-4038-9f87-a20c71dbaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "75c44eff-1977-4bf2-899f-384e515822f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\4227993549.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  df = pd.read_csv(\"D:\\SMS-Data.csv\")  # Replace with your actual file path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     phoneNumber                                    id  \\\n",
      "108   xx80368198  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "274   xx80368198  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "275   xx80368198  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "515   xx80368198  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "1135  xx80368198  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "\n",
      "                          updateAt senderAddress  \\\n",
      "108   Tue, 3 May 2022 08:53:39 UTC     JK-HDBFSL   \n",
      "274   Tue, 3 May 2022 08:53:39 UTC     VD-SPRCRD   \n",
      "275   Tue, 3 May 2022 08:53:39 UTC     VD-SPRCRD   \n",
      "515   Tue, 3 May 2022 08:53:39 UTC     AX-SPRCRD   \n",
      "1135  Tue, 3 May 2022 08:53:39 UTC     CP-UMDHFC   \n",
      "\n",
      "                                                   text  \n",
      "108   Dear Cust, your EMI for HDB Loan a/c 22368264 ...  \n",
      "274   Hi, finance charge of INR 6.00 has been revers...  \n",
      "275   Hi, finance charge of INR 33.00 has been rever...  \n",
      "515   Hi, Late Payment Fee of INR 177.00 has been re...  \n",
      "1135  Dear Customer,EMI of Rs. 5049 for Ummeed Housi...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"D:\\SMS-Data.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Filter rows where 'duedate' is present in the 'text' column (case-insensitive)\n",
    "duedate_rows = df[df['text'].str.contains('due date', case=False, na=False)]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "duedate_rows.to_csv('duedate_rows.csv', index=False)\n",
    "\n",
    "# Display the filtered rows along with column names like 'id' and 'text'\n",
    "print(duedate_rows.head())  # This will show all columns, including 'id', 'text', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "433d3b22-2494-4422-bf4f-f3c9c3c549d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text INR_amount Rs_amount\n",
      "0  Dear Cust, your EMI for HDB Loan a/c 22368264 ...       None      None\n",
      "1  Hi, finance charge of INR 6.00 has been revers...       6.00      None\n",
      "2  Hi, finance charge of INR 33.00 has been rever...      33.00      None\n",
      "3  Hi, Late Payment Fee of INR 177.00 has been re...     177.00      None\n",
      "4  Dear Customer,EMI of Rs. 5049 for Ummeed Housi...       None       504\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('duedate_rows.csv')  # Use your actual file path here\n",
    "\n",
    "# Function to extract amounts with 'INR' and return just the amount\n",
    "def extract_inr_amount(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        # Match 'INR' followed by the amount (excluding INR from the match)\n",
    "        match = re.search(r'INR\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)  # Return just the amount, without INR\n",
    "    return None\n",
    "\n",
    "# Function to extract amounts with 'Rs.' and return just the amount\n",
    "def extract_rs_amount(text):\n",
    "    if isinstance(text, str):  # Ensure text is a string\n",
    "        # Match 'Rs.' followed by the amount (excluding Rs. from the match)\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)  # Return just the amount, without Rs.\n",
    "    return None\n",
    "\n",
    "# Apply the functions to extract amounts for the 'INR_amount' and 'Rs_amount' columns\n",
    "df['INR_amount'] = df['text'].apply(extract_inr_amount)\n",
    "df['Rs_amount'] = df['text'].apply(extract_rs_amount)\n",
    "\n",
    "# Save the filtered data with INR and Rs columns to a new CSV file on the D drive\n",
    "df.to_csv('D:/transaction_statements_with_inr_rs_columns.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df[['text', 'INR_amount', 'Rs_amount']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eb8132ab-1237-4206-b010-7d64ff620628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated IDs and their counts:\n",
      "id\n",
      "af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9    20\n",
      "980b7e48-6e68-495b-a0ab-96a4035da9ef    15\n",
      "ce5f2c8c-6c7f-40a0-9c9f-313aaba39227    15\n",
      "9133ca2a-60af-4d82-8fe6-d6abb06edf24    10\n",
      "48454ae9-67a6-42c0-930b-ddc0d916cca7     8\n",
      "55971a12-2223-4164-97f6-5eaabc77d761     7\n",
      "b8543345-a95c-4b7b-b8ae-d23ffb21cab0     6\n",
      "010a4d48-100b-459f-af7d-5987a995f7f3     5\n",
      "c7d4e612-9eac-4253-a8fc-31ad1cc0edc3     5\n",
      "2278d2ee-67b0-4756-855a-4adb1326bd9f     4\n",
      "02fdaa00-308a-4b79-87ce-d95f35614dc9     3\n",
      "043c058f-8c4e-4d3b-804b-ac07058ceee9     2\n",
      "82dfbac6-ae55-425a-9cfa-0551a3bb309f     2\n",
      "2013df6a-2f7c-43b7-b105-3a177c069dac     2\n",
      "Name: count, dtype: int64\n",
      "Rows with repeated IDs:\n",
      "                                     id  \\\n",
      "0  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "1  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "2  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "3  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "4  af5cdc15-98d7-40c6-a85d-f8bd7ee8f5e9   \n",
      "\n",
      "                                                text  \n",
      "0  Dear Cust, your EMI for HDB Loan a/c 22368264 ...  \n",
      "1  Hi, finance charge of INR 6.00 has been revers...  \n",
      "2  Hi, finance charge of INR 33.00 has been rever...  \n",
      "3  Hi, Late Payment Fee of INR 177.00 has been re...  \n",
      "4  Dear Customer,EMI of Rs. 5049 for Ummeed Housi...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('duedate_rows.csv')  # Replace with your file path\n",
    "\n",
    "# Group by 'id' and count the occurrences\n",
    "id_counts = df['id'].value_counts()\n",
    "\n",
    "# Filter the ids that repeat more than once\n",
    "repeated_ids = id_counts[id_counts > 1]\n",
    "\n",
    "# Display the repeated ids\n",
    "print(\"Repeated IDs and their counts:\")\n",
    "print(repeated_ids)\n",
    "\n",
    "# If you want to see the full rows with repeated ids\n",
    "repeated_rows = df[df['id'].isin(repeated_ids.index)]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "repeated_rows.to_csv('D:/repeated_ids_data.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(\"Rows with repeated IDs:\")\n",
    "print(repeated_rows[['id', 'text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "956c5b79-6fca-4316-a351-8bd0d7079a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text recharge\n",
      "0  Dear Cust, your EMI for HDB Loan a/c 22368264 ...     None\n",
      "1  Hi, finance charge of INR 6.00 has been revers...     None\n",
      "2  Hi, finance charge of INR 33.00 has been rever...     None\n",
      "3  Hi, Late Payment Fee of INR 177.00 has been re...     None\n",
      "4  Dear Customer,EMI of Rs. 5049 for Ummeed Housi...     None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\65408677.py:23: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df.to_csv('D:\\duedate_rows1.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('duedate_rows.csv')  # Replace with your file path\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract the amount after \"Rs.\" when the text contains \"Vodafone\"\n",
    "def extract_vodafone_recharge_amount(text):\n",
    "    if 'vodafone' in text.lower():  # Check if 'vodafone' or 'vodafone idea' is in the text\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)  # Match Rs. followed by the amount\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))  # Extract the amount and convert to float\n",
    "    return None\n",
    "\n",
    "# Apply the function to extract amounts for the 'recharge' column where 'Vodafone' is mentioned\n",
    "df['recharge'] = df['text'].apply(extract_vodafone_recharge_amount)\n",
    "\n",
    "# Display the result\n",
    "print(df[['text', 'recharge']].head())\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df.to_csv('D:\\duedate_rows1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5753d4d6-063f-489a-a1d9-86a75e9ec289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  recharge  cafe_orange  \\\n",
      "0  Paid Rs.470.82 to Vodafone Idea Ltd from Paytm...    470.82          0.0   \n",
      "1  Paid Rs.352.82 to Vodafone Idea Ltd from Paytm...    352.82          0.0   \n",
      "2  Paid Rs.352.82 to Vodafone Idea Ltd from Paytm...    352.82          0.0   \n",
      "3  Paid Rs.352.82 to Vodafone Idea Ltd from Paytm...    352.82          0.0   \n",
      "4  Paid Rs.388.22 to Vodafone Idea Ltd from Paytm...    388.22          0.0   \n",
      "\n",
      "   wallet  other  \n",
      "0  470.82    0.0  \n",
      "1  352.82    0.0  \n",
      "2  352.82    0.0  \n",
      "3  352.82    0.0  \n",
      "4  388.22    0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\maury\\AppData\\Local\\Temp\\ipykernel_16472\\2083795219.py:5: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  df = pd.read_csv(\"D:\\paytm_with_money.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file (replace with your actual file path)\n",
    "df = pd.read_csv(\"D:\\paytm_with_money.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract the amount after \"Rs.\" when the text contains \"Vodafone\" or \"recharge\"\n",
    "def extract_recharge_amount(text):\n",
    "    if 'recharge' in text.lower() or 'vodafone' in text.lower():  # Check if 'recharge' or 'vodafone' is in the text\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)  # Match Rs. followed by the amount\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))  # Extract the amount and convert to float\n",
    "    return 0  # Return 0 instead of None\n",
    "\n",
    "# Function to extract the amount after \"Rs.\" when the text contains \"Cafe Orange\"\n",
    "def extract_cafe_orange_amount(text):\n",
    "    if 'cafe orange' in text.lower():  # Check if 'Cafe Orange' is in the text\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)  # Match Rs. followed by the amount\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))  # Extract the amount and convert to float\n",
    "    return 0  # Return 0 instead of None\n",
    "\n",
    "# Function to extract the amount when the text contains \"Wallet\"\n",
    "def extract_wallet_amount(text):\n",
    "    if 'wallet' in text.lower():  # Check if 'wallet' is mentioned in the text\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)  # Match Rs. followed by the amount\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))  # Extract the amount and convert to float\n",
    "    return 0  # Return 0 instead of None\n",
    "\n",
    "# Function to extract the amount if no other keyword is found (for the \"Other\" column)\n",
    "def extract_other_amount(text):\n",
    "    # If none of the keywords are found, extract any amount from the text\n",
    "    if not any(keyword in text.lower() for keyword in ['recharge', 'vodafone', 'cafe orange', 'wallet']):\n",
    "        match = re.search(r'Rs\\.\\s?(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)', text)  # Match Rs. followed by the amount\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))  # Return the amount found\n",
    "    return 0  # Return 0 if no amount is found\n",
    "\n",
    "# Apply the functions to extract amounts for the respective columns\n",
    "df['recharge'] = df['text'].apply(extract_recharge_amount)  # Extract for recharge (Vodafone, recharge)\n",
    "df['cafe_orange'] = df['text'].apply(extract_cafe_orange_amount)  # Extract for Cafe Orange\n",
    "df['wallet'] = df['text'].apply(extract_wallet_amount)  # Extract for Wallet\n",
    "df['other'] = df['text'].apply(extract_other_amount)  # Extract for Other (when no keywords are found)\n",
    "\n",
    "# Display the result\n",
    "print(df[['text', 'recharge', 'cafe_orange', 'wallet', 'other']].head())\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df.to_csv('D:/updated_data_with_recharge_cafe_orange_wallet_other_columns.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af866bb2-5195-4d6e-88f5-aa5e40891897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa30d07-2eef-4194-b9f4-fdbbcdda4481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
